{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dad80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from Transformer import *\n",
    "\n",
    "from PP import *\n",
    "import math\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Cityscapes\n",
    "from dataloader_cityscapes import *\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2b33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_last_layer(dim_in, stride = [1, 1], padding = [0, 0], dilation = [1, 1], kernel_size = [1, 1], output_padding = [0, 0]):\n",
    "\n",
    "    return ((dim_in + (2 * padding[0]) - (dilation[0] * (kernel_size[0] - 1)) - 1) /  stride[0]) + 1\n",
    "\n",
    "\n",
    "def choose_backbone():\n",
    "\n",
    "    torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "    backbone = torch.nn.Sequential(*(list(torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True).children())[:7]))\n",
    "    backbone.requires_grad = False\n",
    "    return backbone\n",
    "\n",
    "\n",
    "class customVariationalTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        super(customVariationalTransformer, self).__init__()\n",
    "\n",
    "        self.batch_size = kwargs[\"batch_size\"]\n",
    "#         self.backbone = choose_backbone()\n",
    "\n",
    "#         self.backbone_output_dim = functools.reduce(operator.mul, self.backbone(torch.rand(1,\n",
    "#                                     *(kwargs['prior_input_channels'], kwargs['input_img_dim'][0], \n",
    "#                                       kwargs['input_img_dim'][1])))).shape\n",
    "#         self.seq_length = self.backbone_output_dim[0]\n",
    "#         dim1 = prior_last_layer(self.backbone_output_dim[1])\n",
    "#         dim2 = prior_last_layer(self.backbone_output_dim[2])\n",
    "#         last_layer = int(dim1 * dim2)\n",
    "        self.seq_length = 256\n",
    "\n",
    "        layers = list(kwargs['prior_posterior_layers'])\n",
    "\n",
    "        self.decoder_emb = nn.ConvTranspose2d(1, self.seq_length, kernel_size = 1, stride = 1)\n",
    "\n",
    "        self.transformer = Transformer(d_model = 256, nhead = kwargs['transformer_num_heads'],\n",
    "                                        num_encoder_layers = kwargs['transformer_num_encoder_layer'], \n",
    "                                        num_decoder_layers = kwargs['transformer_num_dec_layer'],\n",
    "                                        dim_feedforward = kwargs['transformer_intermediate_layer_dim'], \n",
    "                                        dropout = kwargs['transformer_dropout_per'],\n",
    "                                        activation = \"relu\", return_intermediate_dec = False)\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = kwargs[\"num_cat\"], kernel_size = 3, padding = 1, bias = True),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, img, segm):\n",
    "\n",
    "#         resnet_features = self.backbone(img)\n",
    "#         decoder_embedding = self.decoder_emb(img.unsqueeze(1).view(self.batch_size, 1, int(math.sqrt(img.shape[1])), -1))\n",
    "#         print(resnet_features.contiguous().view(self.batch_size, self.seq_length, -1).shape)\n",
    "#         print(img[:,0,:,:].contiguous().view(self.batch_size, self.seq_length, -1).shape)\n",
    "        reconstruct_posterior = self.transformer.forward(img[:,0,:,:].contiguous().view(self.batch_size, self.seq_length, -1), img[:,0,:,:].contiguous().view(self.batch_size, self.seq_length, -1))\n",
    "        reconstruct_posterior = self.output_layer(reconstruct_posterior.unsqueeze(1))\n",
    "\n",
    "        return reconstruct_posterior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53bb2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_in = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((256,256))\n",
    "])\n",
    "\n",
    "preprocess_ou = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256,256))\n",
    "])\n",
    "\n",
    "tr_loader = CityscapesLoader(\"../datasets/augmented_cityscapes\", transform_in = preprocess_in, \n",
    "                             transform_ou = preprocess_ou)\n",
    "train_loader = DataLoader(dataset = tr_loader, batch_size = 50, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcaa7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = customVariationalTransformer(**{\"input_img_dim\":[256,256],\n",
    "                       \"prior_input_channels\":3, \"prior_posterior_layers\":[64,128,256],\n",
    "                       \"posterior_input_channels\":37, \"batch_size\":50,\n",
    "                        \"transformer_num_heads\":2, \"transformer_num_encoder_layer\":2,\n",
    "                        \"transformer_num_dec_layer\":2,\"transformer_intermediate_layer_dim\":512,\n",
    "                        \"transformer_dropout_per\":0, \"num_cat\": 34})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5c9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lunet/wsmo6/anaconda3/envs/3.6/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(size_average = False, reduce = False, reduction = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75116797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071971893310547\n",
      "0.7072063088417053\n",
      "0.7072041630744934\n",
      "0.7071991562843323\n",
      "0.7071945667266846\n",
      "0.7071843147277832\n",
      "0.7071908116340637\n",
      "0.7071763873100281\n",
      "0.7071744203567505\n",
      "0.707173764705658\n",
      "0.7071672677993774\n",
      "0.7071781754493713\n",
      "0.7071699500083923\n",
      "0.7071511745452881\n",
      "0.7071543335914612\n",
      "0.7071657180786133\n",
      "0.7071362733840942\n",
      "0.7071330547332764\n",
      "0.7071290612220764\n",
      "0.7071396112442017\n",
      "0.7071372270584106\n",
      "0.7071270942687988\n",
      "0.7071239352226257\n",
      "0.7071227431297302\n",
      "0.7071352005004883\n",
      "0.7071274518966675\n",
      "0.7071398496627808\n",
      "0.707119882106781\n",
      "0.7071293592453003\n",
      "0.7071139812469482\n",
      "0.7071263194084167\n",
      "0.7071179747581482\n",
      "0.7071277499198914\n",
      "0.7071271538734436\n",
      "0.7071256637573242\n",
      "0.7071220278739929\n",
      "0.7071253657341003\n",
      "0.707129180431366\n",
      "0.7071071267127991\n",
      "0.7071046829223633\n",
      "0.7071119546890259\n",
      "0.7071231603622437\n",
      "0.7071208357810974\n",
      "0.7071327567100525\n",
      "0.7071077227592468\n",
      "0.7071194052696228\n",
      "0.7071157693862915\n",
      "0.707109808921814\n",
      "0.707104504108429\n",
      "0.7071144580841064\n",
      "0.707116961479187\n",
      "0.7071108222007751\n",
      "0.7071154117584229\n",
      "0.7071051597595215\n",
      "0.7071148753166199\n",
      "0.7071020603179932\n",
      "0.7071037292480469\n",
      "0.707105278968811\n",
      "0.707094132900238\n",
      "0.7071132659912109\n",
      "0.707115113735199\n",
      "0.7071199417114258\n",
      "0.7071073651313782\n",
      "0.7071057558059692\n",
      "0.7071024179458618\n",
      "0.7071227431297302\n",
      "0.7071185111999512\n",
      "0.7071058750152588\n",
      "0.7071191668510437\n",
      "0.7070934176445007\n",
      "0.7071101069450378\n",
      "0.7071067094802856\n",
      "0.7070892453193665\n",
      "0.707115888595581\n",
      "0.707115113735199\n",
      "0.7071020603179932\n",
      "0.7070993185043335\n",
      "0.7071087956428528\n",
      "0.7071069478988647\n",
      "0.7071138024330139\n",
      "0.707098662853241\n",
      "0.7070989608764648\n",
      "0.7070996165275574\n",
      "0.707097589969635\n",
      "0.7071114778518677\n",
      "0.7071201205253601\n",
      "0.7070989608764648\n",
      "0.7071007490158081\n",
      "0.7071176767349243\n",
      "0.7071070671081543\n",
      "0.707088053226471\n",
      "0.7070966362953186\n",
      "0.7070928812026978\n",
      "0.7071094512939453\n",
      "0.7071002125740051\n",
      "0.7071133852005005\n",
      "0.7071056365966797\n",
      "0.7071115970611572\n",
      "0.7071166038513184\n",
      "0.7071033716201782\n",
      "0.7070858478546143\n",
      "0.7070918083190918\n",
      "0.7071096897125244\n",
      "0.7071006894111633\n",
      "0.7070866823196411\n",
      "0.7070906162261963\n",
      "0.7071056962013245\n",
      "0.7070823311805725\n",
      "0.7070876955986023\n",
      "0.7070977687835693\n",
      "0.7070904970169067\n",
      "0.7070895433425903\n",
      "0.7070860266685486\n",
      "0.7070990800857544\n",
      "0.7070898413658142\n",
      "0.7070887684822083\n",
      "0.7070988416671753\n",
      "0.7070817947387695\n",
      "0.7070877552032471\n",
      "0.7071035504341125\n",
      "0.707080066204071\n",
      "0.7070963978767395\n",
      "0.7070972919464111\n",
      "0.7070934176445007\n",
      "0.7070947289466858\n",
      "0.7070978283882141\n",
      "0.7070996165275574\n",
      "0.7070850133895874\n",
      "0.7070934772491455\n",
      "0.7070840001106262\n",
      "0.7070838809013367\n",
      "0.7071044445037842\n",
      "0.7070962190628052\n",
      "0.7070928812026978\n",
      "0.7071017622947693\n",
      "0.7070892453193665\n",
      "0.7070953845977783\n",
      "0.7070996761322021\n",
      "0.7070969343185425\n",
      "0.7070906758308411\n",
      "0.7070827484130859\n",
      "0.7070876955986023\n",
      "0.7070949673652649\n",
      "0.7070785760879517\n",
      "0.7070839405059814\n",
      "0.7070947885513306\n",
      "0.7071014642715454\n",
      "0.7070760726928711\n",
      "0.7070900797843933\n",
      "0.7070867419242859\n",
      "0.707076370716095\n",
      "0.7070904970169067\n",
      "0.707085371017456\n",
      "0.7070860862731934\n",
      "0.7070819735527039\n",
      "0.7070931196212769\n",
      "0.7070708870887756\n",
      "0.7070873975753784\n",
      "0.7070884704589844\n",
      "0.707098126411438\n",
      "0.7070898413658142\n",
      "0.7070766091346741\n",
      "0.7070744037628174\n",
      "0.7070849537849426\n",
      "0.7070695757865906\n",
      "0.7070836424827576\n",
      "0.7070708274841309\n",
      "0.7070687413215637\n",
      "0.7070881128311157\n",
      "0.7070936560630798\n",
      "0.7070884704589844\n",
      "0.7070814967155457\n",
      "0.7070870995521545\n",
      "0.707082211971283\n",
      "0.7070909738540649\n",
      "0.70707768201828\n",
      "0.7070892453193665\n",
      "0.7070659399032593\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1f5e1a2c17aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3.6/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr =  0.0001, weight_decay = 0.)\n",
    "for batch in train_loader:\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "#     prior_latent_space, posterior_latent_space = model.forward(batch['image'], batch['label'])\n",
    "\n",
    "#     kl_loss = torch.mean(kl.kl_divergence(posterior_latent_space, prior_latent_space))\n",
    "#     loss = kl_loss\n",
    "\n",
    "    reconstruct = model.forward(batch['image'], batch['label'])\n",
    "#     print(reconstruct.shape)\n",
    "#     print(batch['label'].shape)\n",
    "    reconstruction_loss = criterion(input = reconstruct, target = batch['label'])\n",
    "    loss = torch.mean(reconstruction_loss)\n",
    "    \n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ac90913",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c97c0abeea26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmylist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmylist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmylist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3.6/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "input_test1 = torch.rand((64,34,256,256))\n",
    "input_test2 = torch.rand((64,34,256,256))\n",
    "mylist = np.array([])\n",
    "np.stack((mylist,input_test1), axis=0)\n",
    "np.stack((mylist, input_test2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c4bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483e528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e356048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfadca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918bb57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6",
   "language": "python",
   "name": "3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
